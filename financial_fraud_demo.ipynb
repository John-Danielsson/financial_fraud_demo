{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting financial fraud using XGBoost and Bayesian Optimization\n",
    "\n",
    "This is a notebook demonstrating how to analyze a dataset and make an XGBoost model using Bayesian Hyperparameter tuning to predict fraud with a high level of accuracy.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. The data\n",
    "\n",
    "2. What is the XGBoost model?\n",
    "\n",
    "3. Parameters of the XGBoost model\n",
    "\n",
    "4. Bayesian Hyperparameter tuning\n",
    "\n",
    "5. Why I use XGBoost and Bayesian Hyperparameter tuning\n",
    "\n",
    "6. Code\n",
    "\n",
    "7. Bibliography"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "The data is a large (493.53 MB) .csv file from kaggle.com ([link](https://www.kaggle.com/code/arjunjoshua/predicting-fraud-in-financial-payment-services/input)).\n",
    "\n",
    "Be sure to download it and put it in the same folder as this demo.\n",
    "\n",
    "## Description\n",
    "\n",
    "Paysim synthetic dataset of mobile money transactions. Each step represents an hour of simulation. This dataset is scaled down 1/4 of the original dataset which is presented in the paper \"PaySim: A financial mobile money simulator for fraud detection\".\n",
    "\n",
    "## Shape\n",
    "\n",
    "rows: 6,362,620\n",
    "\n",
    "columns: 11\n",
    "\n",
    "## Column names\n",
    "\n",
    "### step\n",
    "Maps a unit of time in the real world. In this case 1 step is 1 hour of time.\n",
    "\n",
    "### type\n",
    "Transaction type, either ```\"CASH-IN\"```, ```\"CASH-OUT\"```, ```\"DEBIT\"```, ```\"PAYMENT\"``` or ```\"TRANSFER\"```.\n",
    "\n",
    "### amount\n",
    "The amount of the transaction in local currency.\n",
    "\n",
    "### nameOrig\n",
    "The customer who started the transaction.\n",
    "\n",
    "### oldbalanceOrg\n",
    "The initial balance before the transaction.\n",
    "\n",
    "### newbalanceOrg\n",
    "The customer's balance after the transaction.\n",
    "\n",
    "### nameDest\n",
    "The recipient ID of the transaction.\n",
    "\n",
    "### oldbalanceDest\n",
    "The initial recipient balance before the transaction.\n",
    "\n",
    "### newbalanceDest\n",
    "The recipient's balance after the transaction.\n",
    "\n",
    "### isFraud\n",
    "Identifies a fraudulent transaction (1) and non fraudulent (0)\n",
    "\n",
    "### isFlaggedFraud\n",
    "Flags illegal attempts to transfer more than 200.000 in a single transaction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the XGBoost model?\n",
    "\n",
    "XGBoost stands for e**X**treme **G**radient **Boost**. It's a powerful machine learning algorithm used for classification tasks.\n",
    "\n",
    "XGBoost builds upon 4 things:\n",
    " \n",
    "## 1. Decision trees\n",
    "\n",
    "Decision trees are used for classification tasks. They\"re a series of yes/no (or if/else) questions about the features of the data set you\"re working with.\n",
    "\n",
    "Here\"s a brief explanation:\n",
    "\n",
    "To make a decision tree with a dataset, you do something called _recursive splitting_. For the root node of the tree, you look at the features and their values to find the best way to split the data into 2 homogenous (or as homogenous as possible) chunks. Then you recursively repeat that process until some stopping criterion is met. Below are some examples of stopping criteria:\n",
    "\n",
    "* Maximum depth: the maximum depth of the tree.\n",
    "* Minimum sample size: the minimum number of observations allowed per node.\n",
    "* Minimum impurity: the minimum heterogeneity allowed in a sample, measured in terms of gini impurity or entropy.\n",
    "* Maximum number of leaf nodes: the maximum number of leaf nodes allowed in the tree.\n",
    "\n",
    "\n",
    "## 2. Supervised machine learning\n",
    "\n",
    "SML is a machine learning technique where the model is trained on a dataset whose observations are labeled as belonging to some class. It\"s used for classification tasks.\n",
    "\n",
    "Unsupervised machine learning (UML) is used for discovering patterns in a dataset with no particular target variables in mind. After the patterns are discovered, it\"s up to the data scientist to label the discovered categories.\n",
    "\n",
    "## 3. Ensemble learning\n",
    "\n",
    "A \"meta approach\" to machine learning that uses predictions from different models to arrive at a more accurate prediction. XGBoost is an ensemble of [gradient boosting](https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502) and [decision trees](https://scikit-learn.org/stable/modules/tree.html#:~:text=Decision%20Trees%20(DTs)%20are%20a,as%20a%20piecewise%20constant%20approximation.).\n",
    "\n",
    "## 4. Gradient boosting\n",
    "\n",
    "A classification or regression model that typically uses decision trees (made up of weak predictors) and iteratively updates them. On each iteration, a new weak predictor is added, its predictions are compared to the other predictors, and the model is updated to correct its errors. The model is then updated until some stopping criterion is met, like the number of iterations (see above list of stopping criteria too).\n",
    "\n",
    "For more details, here\"s the [Nvidia glossary page for XGBoost](https://www.nvidia.com/en-us/glossary/data-science/xgboost/#:~:text=XGBoost%2C%20which%20stands%20for%20Extreme,%2C%20classification%2C%20and%20ranking%20problems.). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of the XGBoost model\n",
    "\n",
    "Here are the hyperparameters I will be focusing on:\n",
    "\n",
    "```learning_rate```\n",
    "\n",
    "Controls the step size or shrinkage factor at each boosting iteration. A smaller learning rate can make the model more robust but may require more iterations to converge.\n",
    "\n",
    "```n_estimators```\n",
    "\n",
    "Specifies the number of boosting rounds or decision trees to build. Increasing this value can improve the model\"s performance but may also lead to overfitting if set too high.\n",
    "\n",
    "```max_depth```\n",
    "\n",
    "Sets the maximum depth of each decision tree in the ensemble. Deeper trees can capture more complex interactions but may increase the risk of overfitting.\n",
    "\n",
    "```subsample```\n",
    "\n",
    "Controls the fraction of training instances used for building each tree. Setting a value less than 1.0 introduces randomness and helps prevent overfitting.\n",
    "\n",
    "```colsample_bytree```\n",
    "\n",
    "Specifies the fraction of features or columns used for building each tree. Similar to subsample, it introduces randomness and can prevent overfitting.\n",
    "\n",
    "```gamma```\n",
    "\n",
    "Sets the minimum loss reduction required to split a node further. Higher values make the model more conservative, preventing overfitting, but may result in underfitting if set too high.\n",
    "\n",
    "```lambda or reg_lambda```\n",
    "\n",
    "Controls L2 regularization, also known as the Ridge regularization term. It helps prevent overfitting by adding a penalty term to the loss function.\n",
    "\n",
    "```alpha or reg_alpha```\n",
    "\n",
    "Controls L1 regularization, also known as the Lasso regularization term. It can be used to encourage sparse feature selection and reduce the impact of less important features.\n",
    "\n",
    "```min_child_weight```\n",
    "\n",
    "Specifies the minimum sum of instance weights required to split a node further. Higher values can help prevent overfitting by avoiding splits with low weighted instances.\n",
    "\n",
    "```objective```\n",
    "\n",
    "Defines the loss function to be optimized. It depends on the specific task, such as regression, classification, or ranking. XGBoost provides a range of predefined objectives to choose from.\n",
    "\n",
    "_For more details on the parameters (too many to list here), check out the [documentation](https://xgboost.readthedocs.io/en/stable/parameter.html)._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter Tuning\n",
    "\n",
    "BHT uses Bayesian inference to intelligently search the given hyperparameter space for an optimal set of hyperparameters.\n",
    "\n",
    "Here\"s how it works:\n",
    "\n",
    "1. Define the hyperparameter space by specifying the range or distribution of values for each hyperparameter you want to tune.\n",
    "2. Choose the objective function. This could be mean squared error, accuracy, or F1 score.\n",
    "3. Build an Initial Surrogate Model. This step often uses random forests or Gaussian processes to give an estimate of the objective function.\n",
    "4. Iteratively optimize the model by choosing to either explore (try new hyperparameters) or exploit (keep current, effective, hyperparameters) based on an acquisition function.\n",
    "5. Train and evaluate the model with the selected hyperparameters. This is usually done with validation data or cross validation.\n",
    "6. Use the newly evaluated data to update the model accordingly.\n",
    "7. Repeat steps 4-6 until some stopping criterion is met, like the number of iterations or some pre-defined convergence point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why I use XGBoost and Bayesian Hyperparameter tuning\n",
    "\n",
    "XGBoost is an excellent tool for classification tasks. It is widely used by machine learning engineers and data scientists for production-grade code. Bayesian Hyperparameter Tuning is a smart way to iteratively search for the optimal set of hyperparameters, often requiring fewer iterations than Grid Search Cross Validation or Random Search Cross Validation.\n",
    "\n",
    "This is a strong combination."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "\n",
    "from sys import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "if not \"seaborn\" in modules:\n",
    "    %pip install seaborn\n",
    "import seaborn as sns\n",
    "# if not \"matplotlib\" in modules:\n",
    "#     %pip install matplotlib\n",
    "# import matplotlib as plt\n",
    "if not \"xgboost\" in modules:\n",
    "    %pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "if not \"sklearn\" in modules:\n",
    "    %pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "if not \"hyperopt\" in modules:\n",
    "    %pip install hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# The random state to be used for the whole program.\n",
    "random_state = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the dataset [here](https://www.kaggle.com/code/arjunjoshua/predicting-fraud-in-financial-payment-services/input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PS_20174392719_1491204439457_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Big dataset!\n",
    "# (6362620, 11)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.433972e+02</td>\n",
       "      <td>1.798619e+05</td>\n",
       "      <td>8.338831e+05</td>\n",
       "      <td>8.551137e+05</td>\n",
       "      <td>1.100702e+06</td>\n",
       "      <td>1.224996e+06</td>\n",
       "      <td>1.290820e-03</td>\n",
       "      <td>2.514687e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.423320e+02</td>\n",
       "      <td>6.038582e+05</td>\n",
       "      <td>2.888243e+06</td>\n",
       "      <td>2.924049e+06</td>\n",
       "      <td>3.399180e+06</td>\n",
       "      <td>3.674129e+06</td>\n",
       "      <td>3.590480e-02</td>\n",
       "      <td>1.585775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>1.338957e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.390000e+02</td>\n",
       "      <td>7.487194e+04</td>\n",
       "      <td>1.420800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.327057e+05</td>\n",
       "      <td>2.146614e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>2.087215e+05</td>\n",
       "      <td>1.073152e+05</td>\n",
       "      <td>1.442584e+05</td>\n",
       "      <td>9.430367e+05</td>\n",
       "      <td>1.111909e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>9.244552e+07</td>\n",
       "      <td>5.958504e+07</td>\n",
       "      <td>4.958504e+07</td>\n",
       "      <td>3.560159e+08</td>\n",
       "      <td>3.561793e+08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
       "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
       "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
       "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
       "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
       "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
       "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
       "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
       "\n",
       "       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \n",
       "count    6.362620e+06    6.362620e+06  6.362620e+06    6.362620e+06  \n",
       "mean     1.100702e+06    1.224996e+06  1.290820e-03    2.514687e-06  \n",
       "std      3.399180e+06    3.674129e+06  3.590480e-02    1.585775e-03  \n",
       "min      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "25%      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "50%      1.327057e+05    2.146614e+05  0.000000e+00    0.000000e+00  \n",
       "75%      9.430367e+05    1.111909e+06  0.000000e+00    0.000000e+00  \n",
       "max      3.560159e+08    3.561793e+08  1.000000e+00    1.000000e+00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if anything pops out with basic stats.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig        object \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        object \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at data types.\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data columns\n",
    "### step\n",
    "Maps a unit of time in the real world. In this case 1 step is 1 hour of time.\n",
    "\n",
    "### type\n",
    "CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER\n",
    "\n",
    "### amount\n",
    "Amount of the transaction in local currency.\n",
    "\n",
    "### nameOrig\n",
    "Customer who started the transaction.\n",
    "\n",
    "### oldbalanceOrg\n",
    "Initial balance before the transaction.\n",
    "\n",
    "### newbalanceOrg\n",
    "Customer's balance after the transaction.\n",
    "\n",
    "### nameDest\n",
    "Recipient ID of the transaction.\n",
    "\n",
    "### oldbalanceDest\n",
    "Initial recipient balance before the transaction.\n",
    "\n",
    "### newbalanceDest\n",
    "Recipient's balance after the transaction.\n",
    "\n",
    "### isFraud\n",
    "Identifies a fraudulent transaction (1) and non fraudulent (0).\n",
    "\n",
    "### isFlaggedFraud\n",
    "Flags illegal attempts to transfer more than 200.000 in a single transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step int64 [1 2 3 4 5]\n",
      "type object ['PAYMENT' 'TRANSFER' 'CASH_OUT' 'DEBIT' 'CASH_IN']\n",
      "amount float64 [ 9839.64  1864.28   181.   11668.14  7817.71]\n",
      "nameOrig object ['C1231006815' 'C1666544295' 'C1305486145' 'C840083671' 'C2048537720']\n",
      "oldbalanceOrg float64 [170136.  21249.    181.  41554.  53860.]\n",
      "newbalanceOrig float64 [160296.36  19384.72      0.    29885.86  46042.29]\n",
      "nameDest object ['M1979787155' 'M2044282225' 'C553264065' 'C38997010' 'M1230701703']\n",
      "oldbalanceDest float64 [    0. 21182. 41898. 10845.  5083.]\n",
      "newbalanceDest float64 [     0.    40348.79 157982.12  51513.44  16896.7 ]\n",
      "isFraud int64 [0 1]\n",
      "isFlaggedFraud int64 [0 1]\n"
     ]
    }
   ],
   "source": [
    "# See if any columns should be converted to numerical values.\n",
    "for column in df.columns:\n",
    "    print(column, df.dtypes[column], df[column].unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8213 frauds out of 6362620\n",
      "0.129 %\n"
     ]
    }
   ],
   "source": [
    "# Find out how much fraud occurs.\n",
    "n_frauds = df[df[\"isFraud\"] == 1].shape[0]\n",
    "print(f'{n_frauds} frauds out of {df.shape[0]}')\n",
    "print(f\"{round(100*n_frauds/df.shape[0], 3)}%\")\n",
    "# 8213 frauds out of 6362620\n",
    "# 0.129 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives                     : 16\n",
      "true positives                : 16\n",
      "false positives               : 0\n",
      "true positive rate (precision): 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Find out the true positive rate for flagging transactions as fraud (precision).\n",
    "\n",
    "positive = df[\"isFlaggedFraud\"] == 1\n",
    "positives = df[positive].shape[0]\n",
    "\n",
    "true_positive = positive & (df[\"isFraud\"] == 1)\n",
    "true_positives = df[true_positive].shape[0]\n",
    "\n",
    "false_positives = positives - true_positives\n",
    "\n",
    "print(f\"positives                     : {positives}\")\n",
    "print(f\"true positives                : {true_positives}\")\n",
    "print(f\"false positives               : {false_positives}\")\n",
    "\n",
    "true_positive_rate = 100 * true_positives / positives\n",
    "\n",
    "print(f\"true positive rate (precision): {round(true_positive_rate, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives                      : 6362604\n",
      "true negatives                 : 6354407\n",
      "false negatives                : 8197\n",
      "true negative rate (precision) : 99.871%\n",
      "false negative rate (precision): 0.129%\n"
     ]
    }
   ],
   "source": [
    "# Find out the true negative rate for flagging transactions as fraud (specificity).\n",
    "\n",
    "negative = df[\"isFlaggedFraud\"] == 0\n",
    "negatives = df[negative].shape[0]\n",
    "\n",
    "\n",
    "true_negative = negative & (df[\"isFraud\"] == 0)\n",
    "true_negatives = df[true_negative].shape[0]\n",
    "\n",
    "false_negatives = negatives - true_negatives\n",
    "\n",
    "print(f\"negatives                      : {negatives}\")\n",
    "print(f\"true negatives                 : {true_negatives}\")\n",
    "print(f\"false negatives                : {false_negatives}\")\n",
    "\n",
    "true_negative_rate = 100 * true_negatives / negatives\n",
    "\n",
    "print(f\"true negative rate (specificity) : {round(true_negative_rate, 3)}%\")\n",
    "print(f\"false negative rate              : {round(100-true_negative_rate, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction features and target feature.\n",
    "\n",
    "X = df[df.columns.drop([\"isFraud\", \"isFlaggedFraud\"])].select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ")\n",
    "\n",
    "y = df[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617011</th>\n",
       "      <td>34</td>\n",
       "      <td>1063.07</td>\n",
       "      <td>117577.10</td>\n",
       "      <td>116514.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036091</th>\n",
       "      <td>299</td>\n",
       "      <td>38801.52</td>\n",
       "      <td>5963988.18</td>\n",
       "      <td>6002789.70</td>\n",
       "      <td>608714.36</td>\n",
       "      <td>569912.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126108</th>\n",
       "      <td>236</td>\n",
       "      <td>144875.26</td>\n",
       "      <td>21449.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>144875.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887791</th>\n",
       "      <td>403</td>\n",
       "      <td>178560.07</td>\n",
       "      <td>102622.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1249609.75</td>\n",
       "      <td>1428169.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758918</th>\n",
       "      <td>161</td>\n",
       "      <td>246855.58</td>\n",
       "      <td>78475.00</td>\n",
       "      <td>325330.58</td>\n",
       "      <td>3035577.20</td>\n",
       "      <td>2788721.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "617011     34    1063.07      117577.10       116514.03            0.00   \n",
       "4036091   299   38801.52     5963988.18      6002789.70       608714.36   \n",
       "3126108   236  144875.26       21449.00            0.00            0.00   \n",
       "5887791   403  178560.07      102622.00            0.00      1249609.75   \n",
       "1758918   161  246855.58       78475.00       325330.58      3035577.20   \n",
       "\n",
       "         newbalanceDest  \n",
       "617011             0.00  \n",
       "4036091       569912.85  \n",
       "3126108       144875.26  \n",
       "5887791      1428169.82  \n",
       "1758918      2788721.61  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xg boost\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=.25,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "    'gamma': hp.uniform ('gamma', 1,9),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': 180,\n",
    "    'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=space['n_estimators'],\n",
    "        max_depth=int(space['max_depth']),\n",
    "        gamma=space['gamma'],\n",
    "        reg_alpha=int(space['reg_alpha']),\n",
    "        min_child_weight=int(space['min_child_weight']),\n",
    "        colsample_bytree=int(space['colsample_bytree'])\n",
    "    )\n",
    "    \n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=evaluation,\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least 180 minutes\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_optimized = XGBClassifier(best_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "[Data](https://www.kaggle.com/code/arjunjoshua/predicting-fraud-in-financial-payment-services/input)\n",
    "\n",
    "[Gradient boosting](https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502)\n",
    "\n",
    "[Decision trees](https://scikit-learn.org/stable/modules/tree.html#:~:text=Decision%20Trees%20(DTs)%20are%20a,as%20a%20piecewise%20constant%20approximation.)\n",
    "\n",
    "[Nvidia glossary page for XGBoost](https://www.nvidia.com/en-us/glossary/data-science/xgboost/#:~:text=XGBoost%2C%20which%20stands%20for%20Extreme,%2C%20classification%2C%20and%20ranking%20problems.)\n",
    "\n",
    "[XGBoost documentation](https://xgboost.readthedocs.io/en/stable/parameter.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
